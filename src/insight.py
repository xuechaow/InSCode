# Module name: Insight
#  - encapsualated functions name start with 'i_'
import time
import calendar
import json
import heapq
import math


# function name: utc2utime
# Parameter:<class 'string'> string with UTC time format
# Return: <class 'int'> Unix time in secs from Jan 1, 1970
def i_utc2utime(str_utc):
	tmp_time = time.strptime(str_utc,"%a %b %d %H:%M:%S %z %Y")
	return calendar.timegm(tmp_time)

# function name: load_data
# Parameter: <class 'string'> input file path
# Return: <class 'dict'> valid tweet data as {'hashtags':string[],'created_at':int}

def i_load_data(input_path):
	# Transform file's data into a list of strings of json data
	fp = open(input_path,'r')
	input_data_string = fp.read() # output a string of file content
	input_data_list = input_data_string.split('\n') # output a list of string of file content
	input_json_list = []
	for item in input_data_list: # output a list of json nodes
		try:
			input_json_item = json.loads(item)
			input_json_list.append(input_json_item)
		# When the data file ends with the delimiter, split() function would return a "" which is un-jsonable causing the exception
		except ValueError:
			print("[From Applicant:Xuechao]Format Wrong or End of File, but will continue with loaded data")

	# Dimension reduction: select only necessary data and transform into {tags,time_int} pair	
	tweet_node_list = [] # the list for reduced data in json
	for item in input_json_list:
		tweet_node = {}
		if('created_at' in item):
			tweet_node['created_at'] = i_utc2utime(item['created_at'])
			tweet_node['hashtags'] = []
			for tag in item['entities']['hashtags']:
				# de-deduplicate the tags. Every tag in the hashtag list is unique
				if not (tag['text'] in tweet_node['hashtags']):
					tweet_node['hashtags'].append(tag['text'])
			tweet_node_list.append(tweet_node)

	# close the file object and return the list
	fp.close()
	return tweet_node_list

# function name: create_connect
# Parameter: list of source, dict of destination, key name for dict of destination
# Implementation: Traverse the list_source, for tags not equal to the dict'key(str_key parameter), 
# Return: updated dict in a dictionary
def i_create_connect(list_source,dict_destination,str_key):
	for hashtags in list_source:
		if not(hashtags in dict_destination or hashtags == str_key): # optional: de-dup(hashtags in dict_dest)
			dict_destination[hashtags] = 1

	return dict_destination

# function name: update_connect
# Parameter: list of source, dict of destination, key name for dict of destination
# Implementation: Traverse the list_source, for tags not equal to the dict'key(str_key parameter), initialize with 1 for 
# new tag connection, add with 1 for existed connection.
# Return: updated dict in a dictionary
def i_update_connect(list_source,dict_destination,str_key):
	for hashtags in list_source:
		if not (hashtags == str_key):
			if not(hashtags in dict_destination):
				dict_destination[hashtags] =1
			else:
				dict_destination[hashtags] +=1
	return dict_destination

# function name: delete_connect
# Parameter: list of source, dict of destination, key name for dict of destination
# Implementation: Traverse the list_source, for tags not equal to the dict'key(str_key parameter), subtract the connection count with
# 1, if the count equals to 0, delete this connection
# Return: updated with a deleted dict in a graph, delete source is the list_source
def i_delete_connect(list_source,dict_destination,str_key):
	for hashtags in list_source:
		if not(hashtags == str_key):
			dict_destination[hashtags] -=1
			if(dict_destination[hashtags]==0):
				del dict_destination[hashtags]
	return dict_destination

# function name: 2_digit
# Parameter: the float or int ready to be truncate without rounding up
# Return: a 2-decimal-place float without rounding up
def i_2_digits(i_decimal):
	return math.floor(i_decimal*100)/100

# class name: Data_window
# class variables:
#	- max_timestamp: record the max timestamp
#	- data_heap: the 60 sec window's data in a heap (ordered list)
#	- hashtags_graph: the graph generated by the windowed data
# methods:
#   - update heap
#   - update graph
#   - calculate degree
#   - get methods
class Data_window:
	__max_timestamp = 0
	__data_heap = []
	__hashtags_graph = {}
	__tuple_deleted = [] # need clear to [] after graph updated
	__tuple_inserted = [] # need clear to [] after graph updated

	# function name: updata_heap
	# Parameter: data_item, as a dict {time,taglist}
	# Implementation: if the new tweet's timestamp is greater than the max stamp, update the heap by
	#					- pushing the new tweet (also add to the inserted_list attribute of the class)
	#					- popping the tweets falling out of the new window (also add to the deleted_list attribute of the class)
	#				  if the new timestamp is within the window, add the tweet to inserted list
	#				  if the stamp is out of the window, ignore it
	# Return: none or the heap w/o update
	def update_heap(self,data_item):
	# data_item is {'hashtags':[],'created_at':}
		# updated the max timestamp processed
		tmp_tuple = (data_item['created_at'],data_item['hashtags'])
		if(data_item['created_at'] > self.__max_timestamp):
			self.__max_timestamp = data_item['created_at']
			heapq.heappush(self.__data_heap,tmp_tuple)
			self.__tuple_inserted.append(tmp_tuple)
			while (self.__data_heap[0][0] < self.__max_timestamp-59):
				self.__tuple_deleted.append(heapq.heappop(self.__data_heap))
		else:
			if(data_item['created_at'] < self.__max_timestamp-59):
				return self.__data_heap
			else:
				heapq.heappush(self.__data_heap,tmp_tuple)
				self.__tuple_inserted.append(tmp_tuple)

	# function name: updata_graph
	# Parameter: none
	# Implementation: From the heap updating, we obtain the inserted data tuple (one new tweet), and the deleted tuples.
	# 				  the second item of the tuple is the list for hashtags. To maintain the graph(ignore the single-hashtag list), traverse the new hashtag
	#				  list, update the entry with that tag if the tag exists in the graph dictionary. Create the entry if not.
	#				  For deleting, for each tag in the tag list, decrease the reference count(the value for other tags as key in the dictionary for the selected tag) 
	#                 of that connection by 1
	# Return: none
	def update_graph(self):
		# insertion-update 
		for item_tuple in self.__tuple_inserted: # item_tuple is the item inserted, or the hashtags list
			if not (len(item_tuple[1]) < 2):
				for tags in item_tuple[1]: 
				# item_tuple[1] is the hashtags list of strings, 'tags' is a hashtag. Update the graph with the tags in the
				# inserted list. if the tag is a key of the graph_dict, use update_connection function. if not, use 
				# create_connection function
					if (tags in self.__hashtags_graph):
						self.__hashtags_graph[tags] = i_update_connect(item_tuple[1],self.__hashtags_graph[tags],tags)
					else: 
						#create new dict entry
						self.__hashtags_graph[tags] = {}
						self.__hashtags_graph[tags] = i_create_connect(item_tuple[1],self.__hashtags_graph[tags],tags)
		# delete-update
		for item_tuple in self.__tuple_deleted:
			
			for tags in item_tuple[1]:
			# use the list source(item_tuple[1]) to delete connections. item_tuple[1] contains the connections we need to delete
			# when a node has no connections, delete it
				if (tags in self.__hashtags_graph):
					self.__hashtags_graph[tags] = i_delete_connect(item_tuple[1],self.__hashtags_graph[tags],tags)
					if(len(self.__hashtags_graph[tags]) == 0):
						del self.__hashtags_graph[tags]
		# clear the buffer for update, otherwise would cause data leaking
		self.__tuple_inserted = []
		self.__tuple_deleted = []

	# Implementation: count the keys, sum up the degrees, and divide
	def calculate_average_degree(self):
		key_sum = 0
		degree_sum = 0
		for key in self.__hashtags_graph:
			key_sum +=1
			degree_sum += len(self.__hashtags_graph[key])
		if (key_sum == 0):
			return 0
		else:
			return degree_sum/key_sum
	# Return a private data
	def get_data_heap(self):
		return self.__data_heap
	# Return a private data
	def get_hashtags_graph(self):
		return self.__hashtags_graph








